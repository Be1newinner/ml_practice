{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "417f4712-b938-406c-83b4-c73b779b4b21",
   "metadata": {},
   "source": [
    "# **Understanding Pipelines in Machine Learning**\n",
    "### **What is a Pipeline in Machine Learning?**\n",
    "A **Pipeline** in machine learning is a **sequence of data transformation steps** and model training combined into a single workflow. It automates the entire ML process from **data preprocessing** to **model training and prediction**, ensuring that the same steps are applied consistently.\n",
    "\n",
    "**Key Benefits of Using Pipelines**:\n",
    "‚úÖ **Automation**: Avoid manually applying preprocessing steps repeatedly.  \n",
    "‚úÖ **Consistency**: Ensures transformations are applied uniformly to training and test data.  \n",
    "‚úÖ **Prevents Data Leakage**: Ensures that preprocessing is done within cross-validation and not before.  \n",
    "‚úÖ **Scalability**: Easily integrates new steps or models without rewriting code.  \n",
    "‚úÖ **Efficiency**: Reduces redundancy and speeds up model development.  \n",
    "\n",
    "---\n",
    "\n",
    "## **üìå Why Are Pipelines Important?**\n",
    "### **1Ô∏è‚É£ Preventing Data Leakage**\n",
    "üö® **Problem Without Pipelines**  \n",
    "Imagine applying **scaling** (e.g., `StandardScaler()`) **before** splitting data into training and test sets:\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load dataset\n",
    "X, y = some_dataset\n",
    "\n",
    "# ‚ùå WRONG: Applying Scaling Before Splitting\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)  # The scaler \"sees\" the whole dataset (bad practice)\n",
    "\n",
    "# Now split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "```\n",
    "üî¥ **Issue**: The scaler has **already seen the entire dataset**, including test data.  \n",
    "üî¥ **Data Leakage**: The test set has been influenced by data it should not have seen.\n",
    "\n",
    "‚úÖ **Solution: Use Pipelines**  \n",
    "With a pipeline, transformations are applied **only to training data** before fitting, and the test data transformations are learned **only from the training set**.\n",
    "\n",
    "---\n",
    "\n",
    "## **2Ô∏è‚É£ Building a Simple Pipeline**\n",
    "Let‚Äôs create a pipeline that:\n",
    "1. **Encodes categorical data** (OneHotEncoder).\n",
    "2. **Scales numerical data** (StandardScaler).\n",
    "3. **Trains a Logistic Regression model**.\n",
    "\n",
    "### **Step 1: Import Required Libraries**\n",
    "```python\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Sample Data\n",
    "df = pd.DataFrame({\n",
    "    'Make': ['BMW', 'Honda', 'Nissan', 'Toyota', 'Nissan'],\n",
    "    'Doors': [4, 5, 4, 4, 3],\n",
    "    'Odometer': [50000, 30000, 40000, 60000, 70000],\n",
    "    'Price_Class': [1, 0, 0, 1, 0]  # Target (1 = Expensive, 0 = Cheap)\n",
    "})\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(\"Price_Class\", axis=1)\n",
    "y = df[\"Price_Class\"]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 2: Define Preprocessing Steps**\n",
    "```python\n",
    "# Define categorical and numerical features\n",
    "categorical_features = ['Make']\n",
    "numerical_features = ['Odometer', 'Doors']\n",
    "\n",
    "# Define transformations\n",
    "categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "numerical_transformer = StandardScaler()\n",
    "\n",
    "# Use ColumnTransformer to apply transformations\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', categorical_transformer, categorical_features),\n",
    "    ('num', numerical_transformer, numerical_features)\n",
    "])\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 3: Create and Train the Pipeline**\n",
    "```python\n",
    "# Define a pipeline with preprocessing + model\n",
    "model_pipeline = Pipeline([\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('classifier', LogisticRegression())  # Can swap with other models\n",
    "])\n",
    "\n",
    "# Train the model using the pipeline\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on test data\n",
    "accuracy = model_pipeline.score(X_test, y_test)\n",
    "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
    "```\n",
    "‚úÖ **Now, preprocessing and training are combined into a single step!**\n",
    "\n",
    "---\n",
    "\n",
    "## **3Ô∏è‚É£ More Advanced Pipeline Examples**\n",
    "### **A. Pipeline with Hyperparameter Tuning (GridSearchCV)**\n",
    "```python\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grid for Logistic Regression\n",
    "param_grid = {\n",
    "    'classifier__C': [0.1, 1, 10],  # Regularization strength\n",
    "    'classifier__max_iter': [100, 200]\n",
    "}\n",
    "\n",
    "# Grid search with pipeline\n",
    "grid_search = GridSearchCV(model_pipeline, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best Accuracy: {grid_search.best_score_:.2f}\")\n",
    "```\n",
    "‚úÖ **Pipelines allow easy hyperparameter tuning without manually re-running transformations.**\n",
    "\n",
    "---\n",
    "\n",
    "### **B. Using Different Models in a Pipeline**\n",
    "Instead of **LogisticRegression**, we can easily swap in a **RandomForestClassifier**:\n",
    "```python\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Modify the pipeline to use a different model\n",
    "model_pipeline.set_params(classifier=RandomForestClassifier(n_estimators=100))\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate new model\n",
    "accuracy = model_pipeline.score(X_test, y_test)\n",
    "print(f\"Random Forest Model Accuracy: {accuracy:.2f}\")\n",
    "```\n",
    "‚úÖ **Easily switch models without rewriting preprocessing steps!**\n",
    "\n",
    "---\n",
    "\n",
    "## **4Ô∏è‚É£ When Should You Use a Pipeline?**\n",
    "‚úîÔ∏è **When you have multiple preprocessing steps** (e.g., encoding + scaling).  \n",
    "‚úîÔ∏è **When deploying a model** (ensures consistent transformations).  \n",
    "‚úîÔ∏è **When using cross-validation** (prevents data leakage).  \n",
    "‚úîÔ∏è **When tuning hyperparameters** (GridSearchCV works seamlessly).  \n",
    "\n",
    "---\n",
    "\n",
    "## **5Ô∏è‚É£ Summary of Key Concepts**\n",
    "| **Concept**              | **Explanation**                                                                 |\n",
    "|--------------------------|-------------------------------------------------------------------------------|\n",
    "| **Pipeline**             | Automates the entire ML workflow (preprocessing + training).                  |\n",
    "| **ColumnTransformer**    | Applies different preprocessing steps to different feature types.             |\n",
    "| **Data Leakage**         | Pipelines prevent test data from influencing preprocessing decisions.         |\n",
    "| **Model Flexibility**    | Easily swap models (Logistic Regression ‚Üí Random Forest ‚Üí SVM, etc.).        |\n",
    "| **Hyperparameter Tuning** | Works seamlessly with `GridSearchCV`.                                        |\n",
    "\n",
    "---\n",
    "\n",
    "## **6Ô∏è‚É£ Final Thoughts**\n",
    "üöÄ **Pipelines are an essential best practice in ML** for making models **efficient, scalable, and reusable**.  \n",
    "Would you like to see **how to save and load pipelines for deployment**? üòä"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af2be63-7ec3-4362-b670-8bd99e1d7c10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
